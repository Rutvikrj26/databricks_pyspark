{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n",
    "\n",
    "This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Shakespeare', 22)\n",
       "('GUTENBERG', 100)\n",
       "('WILLIAM', 128)\n",
       "('WORLD', 98)\n",
       "('COLLEGE', 98)\n",
       "('When', 406)\n",
       "('Lord', 402)\n",
       "('Library', 5)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "('Shakespeare', 22)\n('GUTENBERG', 100)\n('WILLIAM', 128)\n('WORLD', 98)\n('COLLEGE', 98)\n('When', 406)\n('Lord', 402)\n('Library', 5)\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "#all spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    " \n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# File location and type\n",
    "file_location = \"/FileStore/tables/shakespeare_1.txt\"\n",
    "text= sc.textFile(file_location)\n",
    "given_words=\"Shakespeare,When,Lord,Library,GUTENBERG,WILLIAM,COLLEGE,WORLD\"\n",
    "given_words=given_words.split(\",\")\n",
    "#print(given_words)\n",
    "\n",
    "def clean_data(s):\n",
    "    data=s.strip(string.punctuation)\n",
    "    return(data)\n",
    "\n",
    "df=text.map(clean_data)\n",
    "#print(df.collect())\n",
    "df=df.flatMap(lambda x: re.split(r\"\\W+\",x))\n",
    "#print(df.collect())\n",
    "df=df.filter(lambda x : len(x)>1)\n",
    "df=df.map(lambda word :(word,1))\n",
    "df=df.reduceByKey(lambda a,b:a+b)\n",
    "#print(df.collect())\n",
    "\n",
    "for i in df.collect():\n",
    "    if i[0] in given_words:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bf5fa96d-6165-477e-888b-37879bfffba8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**please note that this result is based on the assumption that WORLD is not same as  \"World\", \"world.\". The data has been convereted to lowercase stripped om punctuation to get this results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8505fbf1-062e-4c99-ace7-16a8d3db6562",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bottom 20 words are:\n",
       "[('anyone', 1), ('restrictions', 1), ('online', 1), ('www', 1), ('gutenberg', 1), ('org', 1), ('COPYRIGHTED', 1), ('Details', 1), ('guidelines', 1), ('Posting', 1), ('2011', 1), ('EBook', 1), ('January', 1), ('1994', 1), ('Character', 1), ('encoding', 1), ('cooperation', 1), ('Public', 1), ('Domain', 1), ('implications', 1)]\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "bottom 20 words are:\n[('anyone', 1), ('restrictions', 1), ('online', 1), ('www', 1), ('gutenberg', 1), ('org', 1), ('COPYRIGHTED', 1), ('Details', 1), ('guidelines', 1), ('Posting', 1), ('2011', 1), ('EBook', 1), ('January', 1), ('1994', 1), ('Character', 1), ('encoding', 1), ('cooperation', 1), ('Public', 1), ('Domain', 1), ('implications', 1)]\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res=df.sortBy(lambda x : x[1]).collect()\n",
    "print(\"bottom 20 words are:\")\n",
    "print(res[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b316f8db-6656-4212-80c6-47c0cd7f0d2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Top 20 words in ascending order are:\n",
       "[('him', 2527), ('this', 2609), ('for', 2713), ('your', 2797), ('be', 2986), ('it', 3078), ('with', 3221), ('his', 3278), ('me', 3448), ('not', 3595), ('is', 3722), ('And', 3735), ('that', 3864), ('in', 4803), ('my', 4922), ('you', 5360), ('to', 7742), ('of', 7968), ('and', 8942), ('the', 11412)]\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Top 20 words in ascending order are:\n[('him', 2527), ('this', 2609), ('for', 2713), ('your', 2797), ('be', 2986), ('it', 3078), ('with', 3221), ('his', 3278), ('me', 3448), ('not', 3595), ('is', 3722), ('And', 3735), ('that', 3864), ('in', 4803), ('my', 4922), ('you', 5360), ('to', 7742), ('of', 7968), ('and', 8942), ('the', 11412)]\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Top 20 words in ascending order are:\")\n",
    "print(res[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b21f52f0-e819-42a3-bb5b-68916d5c7379",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Q3_Q4-Option-2",
   "notebookOrigID": 2874138219874388,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
